#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepFaceæ£€æµ‹å’Œé˜²å¾¡ç³»ç»Ÿ - ç²¾ç®€ç‰ˆ
ç”¨äºè¯†åˆ«å’Œé˜²å¾¡åŸºäºDeepFaceçš„AIè¯ˆéª—æ”»å‡»
"""

import os
import json
import time
import cv2
import numpy as np
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
from collections import deque
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('anti_deepface.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DetectionLevel(Enum):
    """æ£€æµ‹çº§åˆ«æšä¸¾"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AttackType(Enum):
    """æ”»å‡»ç±»å‹æšä¸¾"""
    DEEPFAKE = "deepfake"
    SPOOFING = "spoofing"
    REPLAY = "replay"
    ADVERSARIAL = "adversarial"

@dataclass
class DetectionResult:
    """æ£€æµ‹ç»“æœæ•°æ®ç±»"""
    is_deepface: bool
    confidence: float
    attack_type: Optional[AttackType]
    detection_level: DetectionLevel
    details: Dict[str, Any]
    timestamp: float
    frame_id: Optional[int] = None

@dataclass
class SecurityConfig:
    """å®‰å…¨é…ç½®æ•°æ®ç±»"""
    confidence_threshold: float = 0.7
    alert_threshold: float = 0.9
    time_window_seconds: int = 30
    max_frames_per_window: int = 100

class DeepFaceDetector:
    """DeepFaceæ£€æµ‹å™¨ä¸»ç±»"""
    
    def __init__(self, config: SecurityConfig = None):
        self.config = config or SecurityConfig()
        self.detection_history = deque(maxlen=1000)
        self.alert_history = deque(maxlen=100)
        logger.info("DeepFaceæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def detect_frame(self, frame: np.ndarray, frame_id: int = None) -> DetectionResult:
        """æ£€æµ‹å•å¸§å›¾åƒ"""
        start_time = time.time()
        
        # å¤šç»´åº¦æ£€æµ‹
        detection_results = {}
        
        # 1. å›¾åƒè´¨é‡æ£€æµ‹
        detection_results['image_quality'] = self._check_image_quality(frame)
        
        # 2. ç»Ÿè®¡ç‰¹æ€§æ£€æµ‹
        detection_results['statistical'] = self._check_statistical_properties(frame)
        
        # 3. é¢‘åŸŸç‰¹å¾æ£€æµ‹
        detection_results['frequency'] = self._check_frequency_domain(frame)
        
        # 4. å™ªå£°æ¨¡å¼æ£€æµ‹
        detection_results['noise_pattern'] = self._check_noise_patterns(frame)
        
        # ç»¼åˆè¯„ä¼°
        final_result = self._aggregate_results(detection_results, frame_id)
        final_result.timestamp = start_time
        
        # è®°å½•æ£€æµ‹å†å²
        self.detection_history.append(final_result)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ¥è­¦
        if final_result.is_deepface and final_result.confidence > self.config.alert_threshold:
            self._trigger_alert(final_result)
        
        return final_result
    
    def _check_image_quality(self, frame: np.ndarray) -> Dict[str, Any]:
        """æ£€æŸ¥å›¾åƒè´¨é‡"""
        if frame is None:
            return {'confidence': 0.0, 'details': {'method': 'image_quality'}}
        
        # è®¡ç®—æ¸…æ™°åº¦
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # æ£€æŸ¥åˆ†è¾¨ç‡
        height, width = frame.shape[:2]
        resolution_score = min(width * height / (1920 * 1080), 1.0)
        
        # æ£€æŸ¥äº®åº¦
        brightness = np.mean(gray)
        brightness_score = 1.0 if 50 < brightness < 200 else 0.5
        
        # ç»¼åˆè¯„åˆ†
        quality_score = (laplacian_var / 1000) * 0.4 + resolution_score * 0.3 + brightness_score * 0.3
        return {
            'confidence': min(quality_score, 1.0),
            'details': {
                'method': 'image_quality',
                'laplacian_var': laplacian_var,
                'resolution_score': resolution_score,
                'brightness_score': brightness_score
            }
        }
    
    def _check_statistical_properties(self, frame: np.ndarray) -> Dict[str, Any]:
        """æ£€æŸ¥ç»Ÿè®¡ç‰¹æ€§"""
        if frame is None:
            return {'confidence': 0.0, 'details': {'method': 'statistical'}}
        
        channels = cv2.split(frame)
        anomalies = 0
        
        for channel in channels:
            # æ£€æŸ¥åƒç´ å€¼åˆ†å¸ƒ
            hist = cv2.calcHist([channel], [0], None, [256], [0, 256])
            hist = hist.flatten()
            
            # æ£€æŸ¥åˆ†å¸ƒæ˜¯å¦è¿‡äºå‡åŒ€ï¼ˆå¯èƒ½æ˜¯ç”Ÿæˆçš„ï¼‰
            hist_std = np.std(hist)
            hist_mean = np.mean(hist)
            
            if hist_std < hist_mean * 0.1:  # åˆ†å¸ƒè¿‡äºå‡åŒ€
                anomalies += 1
        
        # å¼‚å¸¸è¶Šå¤šï¼Œè¶Šå¯èƒ½æ˜¯DeepFace
        confidence = min(anomalies / len(channels), 1.0)
        return {
            'confidence': confidence,
            'details': {
                'method': 'statistical',
                'anomalies': anomalies,
                'total_channels': len(channels)
            }
        }
    
    def _check_frequency_domain(self, frame: np.ndarray) -> Dict[str, Any]:
        """æ£€æŸ¥é¢‘åŸŸç‰¹å¾"""
        if frame is None:
            return {'confidence': 0.0, 'details': {'method': 'frequency'}}
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # è®¡ç®—FFT
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        magnitude_spectrum = np.log(np.abs(f_shift) + 1)
        
        # æ£€æŸ¥é«˜é¢‘æˆåˆ†
        height, width = magnitude_spectrum.shape
        center_y, center_x = height // 2, width // 2
        
        # è®¡ç®—é«˜é¢‘åŒºåŸŸ
        high_freq_region = magnitude_spectrum[
            center_y-height//4:center_y+height//4,
            center_x-width//4:center_x+width//4
        ]
        
        # é«˜é¢‘æˆåˆ†å¼‚å¸¸å¯èƒ½è¡¨ç¤ºå¯¹æŠ—æ ·æœ¬
        high_freq_mean = np.mean(high_freq_region)
        confidence = min(high_freq_mean / 10, 1.0)
        
        return {
            'confidence': confidence,
            'details': {
                'method': 'frequency',
                'high_freq_mean': high_freq_mean
            }
        }
    
    def _check_noise_patterns(self, frame: np.ndarray) -> Dict[str, Any]:
        """æ£€æŸ¥å™ªå£°æ¨¡å¼"""
        if frame is None:
            return {'confidence': 0.0, 'details': {'method': 'noise_pattern'}}
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢è®¡ç®—å™ªå£°
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        noise = cv2.absdiff(gray, blurred)
        noise_level = np.mean(noise)
        
        # å™ªå£°æ°´å¹³è¿‡ä½å¯èƒ½è¡¨ç¤ºå›¾åƒè¢«è¿‡åº¦å¤„ç†
        if noise_level < 5:
            confidence = 0.8
        elif noise_level > 50:
            confidence = 0.6
        else:
            confidence = 0.2
        
        return {
            'confidence': confidence,
            'details': {
                'method': 'noise_pattern',
                'noise_level': noise_level
            }
        }
    
    def _aggregate_results(self, results: Dict[str, Dict], frame_id: int) -> DetectionResult:
        """èšåˆå¤šä¸ªæ¨¡å—çš„æ£€æµ‹ç»“æœ"""
        # æƒé‡é…ç½®
        weights = {
            'image_quality': 0.3,
            'statistical': 0.25,
            'frequency': 0.2,
            'noise_pattern': 0.25
        }
        
        total_confidence = 0.0
        total_weight = 0.0
        details = {}
        
        for module_name, result in results.items():
            weight = weights.get(module_name, 0.1)
            confidence = result.get('confidence', 0.0)
            
            total_confidence += confidence * weight
            total_weight += weight
            details[module_name] = result.get('details', {})
        
        if total_weight > 0:
            final_confidence = total_confidence / total_weight
        else:
            final_confidence = 0.0
        
        # ç¡®å®šæ£€æµ‹çº§åˆ«
        if final_confidence >= 0.9:
            level = DetectionLevel.CRITICAL
        elif final_confidence >= 0.7:
            level = DetectionLevel.HIGH
        elif final_confidence >= 0.5:
            level = DetectionLevel.MEDIUM
        else:
            level = DetectionLevel.LOW
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºDeepFace
        is_deepface = final_confidence >= self.config.confidence_threshold
        
        # ç¡®å®šæ”»å‡»ç±»å‹
        attack_type = self._determine_attack_type(details)
        
        return DetectionResult(
            is_deepface=is_deepface,
            confidence=final_confidence,
            attack_type=attack_type,
            detection_level=level,
            details=details,
            frame_id=frame_id
        )
    
    def _determine_attack_type(self, details: Dict[str, Dict]) -> Optional[AttackType]:
        """ç¡®å®šæ”»å‡»ç±»å‹"""
        # åŸºäºæ£€æµ‹è¯¦æƒ…åˆ¤æ–­æ”»å‡»ç±»å‹
        if details.get('frequency', {}).get('high_freq_mean', 0) > 8:
            return AttackType.ADVERSARIAL
        elif details.get('statistical', {}).get('anomalies', 0) >= 2:
            return AttackType.DEEPFAKE
        elif details.get('noise_pattern', {}).get('noise_level', 0) < 5:
            return AttackType.SPOOFING
        else:
            return AttackType.DEEPFAKE
    
    def _trigger_alert(self, result: DetectionResult):
        """è§¦å‘å®‰å…¨æŠ¥è­¦"""
        alert = {
            'timestamp': time.time(),
            'frame_id': result.frame_id,
            'confidence': result.confidence,
            'attack_type': result.attack_type.value if result.attack_type else None,
            'detection_level': result.detection_level.value
        }
        self.alert_history.append(alert)
        logger.warning(f"ğŸš¨ å®‰å…¨æŠ¥è­¦: æ£€æµ‹åˆ°DeepFaceä½¿ç”¨ï¼ç½®ä¿¡åº¦: {result.confidence:.3f}")
    
    def detect_video(self, video_path: str) -> List[DetectionResult]:
        """æ£€æµ‹è§†é¢‘ä¸­çš„DeepFaceä½¿ç”¨"""
        results = []
        
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                result = self.detect_frame(frame, frame_count)
                results.append(result)
                
                # å®æ—¶æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                if result.is_deepface:
                    logger.warning(f"å¸§ {frame_count}: æ£€æµ‹åˆ°DeepFaceä½¿ç”¨ï¼Œç½®ä¿¡åº¦: {result.confidence:.3f}")
                
                # æ¯100å¸§è¾“å‡ºä¸€æ¬¡è¿›åº¦
                if frame_count % 100 == 0:
                    logger.info(f"å·²å¤„ç† {frame_count} å¸§")
        
        finally:
            cap.release()
        
        return results
    
    def get_detection_statistics(self) -> Dict[str, Any]:
        """è·å–æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        if not self.detection_history:
            return {}
        
        total_detections = len(self.detection_history)
        deepface_detections = sum(1 for r in self.detection_history if r.is_deepface)
        
        confidence_scores = [r.confidence for r in self.detection_history]
        
        return {
            'total_frames': total_detections,
            'deepface_detections': deepface_detections,
            'detection_rate': deepface_detections / total_detections if total_detections > 0 else 0,
            'avg_confidence': np.mean(confidence_scores),
            'max_confidence': np.max(confidence_scores),
            'min_confidence': np.min(confidence_scores)
        }
    
    def export_results(self, output_path: str):
        """å¯¼å‡ºæ£€æµ‹ç»“æœ"""
        results = {
            'config': self.config.__dict__,
            'statistics': self.get_detection_statistics(),
            'detections': [
                {
                    'frame_id': r.frame_id,
                    'timestamp': r.timestamp,
                    'is_deepface': r.is_deepface,
                    'confidence': r.confidence,
                    'attack_type': r.attack_type.value if r.attack_type else None,
                    'detection_level': r.detection_level.value,
                    'details': r.details
                }
                for r in self.detection_history
            ],
            'alerts': list(self.alert_history)
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"æ£€æµ‹ç»“æœå·²å¯¼å‡ºåˆ°: {output_path}")

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    detector = DeepFaceDetector()
    print("DeepFaceæ£€æµ‹å’Œé˜²å¾¡ç³»ç»Ÿå·²å¯åŠ¨")
    print("è¯·ä½¿ç”¨ detect_video() æ–¹æ³•æ£€æµ‹è§†é¢‘æ–‡ä»¶")
